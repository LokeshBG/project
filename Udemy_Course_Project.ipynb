{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://www.cs.toronto.edu/~kriz/cifar.html, this is the link to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# got the below code snippet from the above website\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CIFAR_DIR = 'cifar-10-batches-py/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirs = ['batches.meta','data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5','test_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a list to copy the data in the subsequent steps\n",
    "all_data = [0,1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,direc in zip(all_data, dirs):\n",
    "    all_data[i] = unpickle(CIFAR_DIR + direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy the data in all_data[i] to different variables, so that its easy to process \n",
    "batch_meta = all_data[0]\n",
    "data_batch1 = all_data[1]\n",
    "data_batch2 = all_data[2]\n",
    "data_batch3 = all_data[3]\n",
    "data_batch4 = all_data[4]\n",
    "data_batch5 = all_data[5]\n",
    "test_batch = all_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_cases_per_batch': 10000,\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print (batch_meta)\n",
    "batch_meta\n",
    "#gives a dictionary with the keys as: label names, num_cases_for_batch, number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'label_names', b'num_vis', b'num_cases_per_batch'])\n"
     ]
    }
   ],
   "source": [
    "print (batch_meta.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'data', b'labels', b'filenames', b'batch_label'])\n"
     ]
    }
   ],
   "source": [
    "print (data_batch1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data_batch1 Matrix is (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "#Grab a single image from one of the batches and Display that image\n",
    "# \n",
    "X = data_batch1[b'data'] # b is important\n",
    "print(\"The size of the data_batch1 Matrix is\",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reshaped Matrix is of the size (3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "#Reshape the image so that its size is: 32*32, since its a color image, \n",
    "# we keep the 3 channels (RGB)\n",
    "X = X.reshape(10000,3,32,32)#.transpose(0,2,3,1).astype(\"uint8\")\n",
    "print (\"The reshaped Matrix is of the size\",X[0].shape)\n",
    "# transpose the matrix, since the imshow command accepts commands in the form of (Height, Width, Channels)\n",
    "X = X.transpose(0,2,3,1).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2c9e36dda0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBQ5vxAJRc4vREL5/49Zfxs1RhCbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c9e726ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display any one image from batch_1\n",
    "plt.imshow(X[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manipulate the data for ease of processing\n",
    "def one_hot(vector, values = 10):\n",
    "    n = len(vector)\n",
    "    out = np.zeros((n, values))\n",
    "    print (out)\n",
    "    range(n)\n",
    "    out[range(n),vector] = 1\n",
    "    return out\n",
    "#one_hot([1,2,3,4,5,6,7,8,8,9,1], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helper_functions():\n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        #grabs a list of all the data batches for training\n",
    "        self.all_train_batches = [data_batch1,data_batch2,data_batch3,data_batch4,data_batch5]\n",
    "        # grab a list of the one test batch\n",
    "        self.test_batch = [test_batch]\n",
    "        # Initialize empty variables for later use\n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        self.test_images = None\n",
    "        self.test_labels = None\n",
    "        \n",
    "    def set_up_images(self):\n",
    "        print(\"setting training images and labels\")\n",
    "        #vertically stacks the training images\n",
    "        self.training_images = np.vstack(d[b\"data\"] for d in self.all_train_batches)\n",
    "        train_len = len(self.training_images)\n",
    "        \n",
    "        #reshape and normalize the training images\n",
    "        self.training_images = self.training_images.reshape(train_len, 3,32,32).transpose(0,2,3,1)/255\n",
    "        # one hot encodes the training labels \n",
    "        self.training_labels = one_hot(np.hstack([d[b\"labels\"] for d in self.all_train_batches]),10)\n",
    "        \n",
    "        print (\"setting up test images and labels\")\n",
    "        #vertically stacks the testing images\n",
    "        self.test_images = np.vstack(d[b\"data\"] for d in self.test_batch)\n",
    "        test_len = len(self.test_images)\n",
    "        \n",
    "        #reshape and normalize the training images\n",
    "        self.test_images = self.test_images.reshape(test_len, 3,32,32).transpose(0,2,3,1)/255\n",
    "        # one hot encodes the training labels \n",
    "        self.test_labels = one_hot(np.hstack([d[b\"labels\"] for d in self.test_batch]), 10)\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        #Assuimg a batch size of 100\n",
    "        x = self.training_images[self.i : self.i+batch_size].reshape(100,32,32,3)\n",
    "        y = self.training_labels[self.i : self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x,y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting training images and labels\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "setting up test images and labels\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "ch = Helper_functions()\n",
    "ch.set_up_images()\n",
    "# to get the next batch use\n",
    "batch = ch.next_batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create two placeholders x and y_true as usual\n",
    "x = tf.placeholder(tf.float32, shape = [None, 32,32,3])\n",
    "y_true = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "\n",
    "#create one more placeholder, hold_probability. \n",
    "#There is no need of shape here, this placeholder will hold a single probability of the dropout.\n",
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# 1. initialize the weights\n",
    "# 2. initialize the bias\n",
    "# 3. conv2d\n",
    "# 4. max_pool_2by2\n",
    "# 5. convolutional layer\n",
    "# 6. normal_full_layer\n",
    "\n",
    "def init_weights(shape):\n",
    "    init_random_dist  = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W,strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "# First convolutional layer\n",
    "convo_1 = convolutional_layer(x, shape = [4,4,3,32])\n",
    "# pooling layer\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the next convolutional layers\n",
    "convo_2 = convolutional_layer(convo_1_pooling, shape = [4,4,32,64])\n",
    "convo_2_pooling  = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convo_2 to flat\n",
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1, 8*8*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create  a new full layer using the normal_full_layer function\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the dropout layer\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loss Function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_true, logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a variable to initialize all global tf variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP: 0\n"
     ]
    }
   ],
   "source": [
    "# Graph session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(5000):\n",
    "        batch = ch.next_batch(100)\n",
    "        sess.run(train, feed_dict={x:batch[0], y_true:batch[1], hold_prob:0.5})\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print (\"STEP: {}\".format(i))\n",
    "            matches = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            print(sess.run(acc, feed_dict={x:ch.test_images, y_true:ch.test_labels, hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:virtual_environment]",
   "language": "python",
   "name": "conda-env-virtual_environment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
